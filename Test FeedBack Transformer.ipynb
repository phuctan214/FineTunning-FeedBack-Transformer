{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Test FeedBack Transformer.ipynb","provenance":[],"mount_file_id":"1qGlpQ3dZ4kjvgo8yDQ_t_AAms3uAYz9F","authorship_tag":"ABX9TyPqO47slDJQejo5F8TXdygX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bDK5dADAFwqo","executionInfo":{"status":"ok","timestamp":1617071930926,"user_tz":-420,"elapsed":1249,"user":{"displayName":"Poeta El","photoUrl":"","userId":"07945809110756503030"}},"outputId":"d9cfeee8-4be0-4921-9025-ab382106e826"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Tue Mar 30 02:33:54 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   49C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MyQUR2cXGTgC","executionInfo":{"status":"ok","timestamp":1617071948759,"user_tz":-420,"elapsed":15857,"user":{"displayName":"Poeta El","photoUrl":"","userId":"07945809110756503030"}},"outputId":"1dea2517-d0f4-4bef-b525-26114ac08872"},"source":["!pip install feedback-transformer-pytorch\n","!pip install transformers\n","!pip install torchtext"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting feedback-transformer-pytorch\n","  Downloading https://files.pythonhosted.org/packages/bb/7d/123e05d42d6a23d2b3a2a0031a35f81baaf74a3489134b4b0fe6792991cb/feedback_transformer_pytorch-0.0.11-py3-none-any.whl\n","Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from feedback-transformer-pytorch) (1.8.0+cu101)\n","Collecting einops\n","  Downloading https://files.pythonhosted.org/packages/5d/a0/9935e030634bf60ecd572c775f64ace82ceddf2f504a5fd3902438f07090/einops-0.3.0-py2.py3-none-any.whl\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6->feedback-transformer-pytorch) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.6->feedback-transformer-pytorch) (1.19.5)\n","Installing collected packages: einops, feedback-transformer-pytorch\n","Successfully installed einops-0.3.0 feedback-transformer-pytorch-0.0.11\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/d5/f4157a376b8a79489a76ce6cfe147f4f3be1e029b7144fa7b8432e8acb26/transformers-4.4.2-py3-none-any.whl (2.0MB)\n","\u001b[K     |████████████████████████████████| 2.0MB 5.5MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 35.8MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 28.8MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=4dc99b0b9f2a497e72241aabd3ffdb201140cf8515b4b81aa7e3a491c8569851\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.4.2\n","Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.9.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n","Requirement already satisfied: torch==1.8.0 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.8.0+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.19.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->torchtext) (3.7.4.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wCQRPozKGct_","executionInfo":{"status":"ok","timestamp":1617071956809,"user_tz":-420,"elapsed":1140,"user":{"displayName":"Poeta El","photoUrl":"","userId":"07945809110756503030"}},"outputId":"b0929546-3424-4829-9beb-16313a5a08a7"},"source":["%cd '/content/drive/MyDrive'\n","!ls"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive\n","'Colab Notebooks'  'FeedBack Transformer'   Tokenizer_26_03\n"," Data\t\t    GPT-2\t\t    VnCoreNLP-master\n"," Đức\t\t    PhoBERT_base_fairseq\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CaDiC4MzGfSz","executionInfo":{"status":"ok","timestamp":1617071965819,"user_tz":-420,"elapsed":3780,"user":{"displayName":"Poeta El","photoUrl":"","userId":"07945809110756503030"}}},"source":["import torch\n","from transformers import AutoModel, AutoTokenizer\n","from feedback_transformer_pytorch import FeedbackTransformer\n","from transformers import RobertaTokenizerFast\n","import os\n","import torch\n","from torch.utils.data.dataset import Dataset\n","from transformers.tokenization_utils import PreTrainedTokenizer\n","from filelock import FileLock\n","from transformers.utils import logging\n","from typing import Dict, List, Optional\n","import pickle\n","import random\n","import time\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import torch.optim as optim\n","from pathlib import Path\n","import numpy as np"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"j5mwZHBOGgo_","executionInfo":{"status":"ok","timestamp":1617072003084,"user_tz":-420,"elapsed":2151,"user":{"displayName":"Poeta El","photoUrl":"","userId":"07945809110756503030"}}},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","tokenizer = RobertaTokenizerFast.from_pretrained(\"./Tokenizer_26_03\", max_len=512)\n","tokenizer.add_tokens('\\n')\n","vocab_size= tokenizer.vocab_size\n","vocab_size = vocab_size + 1"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"tlCT23U4GqVh","executionInfo":{"status":"ok","timestamp":1617072012988,"user_tz":-420,"elapsed":7351,"user":{"displayName":"Poeta El","photoUrl":"","userId":"07945809110756503030"}}},"source":["import torch\n","from feedback_transformer_pytorch import FeedbackTransformer\n","\n","device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n","\n","model = FeedbackTransformer(\n","    num_tokens = vocab_size,           # number of tokens\n","    dim = 512,                    # dimension\n","    depth = 6,                    # depth\n","    seq_len = 8,                  # the sequence length of each segment or window\n","    mem_len = 256,                # length of the memory buffer\n","    dim_head = 64,                # dimension of each head\n","    heads = 8,                    # number of heads\n","    attn_dropout = 0.1,           # attention dropout\n","    ff_dropout = 0.1              # feedforward dropout\n",").to(device)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AF5BCxM8Gtc9","executionInfo":{"status":"ok","timestamp":1617072040957,"user_tz":-420,"elapsed":750,"user":{"displayName":"Poeta El","photoUrl":"","userId":"07945809110756503030"}},"outputId":"8e598f19-510d-4654-bcf6-f7513bd08f32"},"source":["lr_rate = 0.0001\n","criterion = nn.CrossEntropyLoss().to(device)\n","optimizer = optim.Adam(model.parameters(), lr_rate)\n","nn.CrossEntropyLoss(ignore_index = tokenizer.pad_token_id).to(device)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CrossEntropyLoss()"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"W-PehoysGv8Z","executionInfo":{"status":"ok","timestamp":1617073134779,"user_tz":-420,"elapsed":957,"user":{"displayName":"Poeta El","photoUrl":"","userId":"07945809110756503030"}}},"source":["def save_checkpoint(state, filename= \"FeedBack Transformer/feedback_transformer_checkpoint_update.pth.tar\"):\n","    print(\"Saving checkpoint\")\n","    torch.save(state,filename)\n","\n","def load_checkpoint(state):\n","    print(\"Load checkpoint\")\n","    model.load_state_dict(state['state_dict'])\n","    optimizer.load_state_dict(state['optimizer'])\n"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fzzrCrEkGzFJ","executionInfo":{"status":"ok","timestamp":1617073156998,"user_tz":-420,"elapsed":20522,"user":{"displayName":"Poeta El","photoUrl":"","userId":"07945809110756503030"}},"outputId":"82c33b57-6036-423e-8bc0-f1417134874d"},"source":["load_checkpoint(torch.load(\"FeedBack Transformer/feedback_transformer_checkpoint_update.pth.tar\"))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Load checkpoint\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rvADq49uG2Fp","executionInfo":{"status":"ok","timestamp":1617073173113,"user_tz":-420,"elapsed":962,"user":{"displayName":"Poeta El","photoUrl":"","userId":"07945809110756503030"}}},"source":["class TextGenerator():\n","\n","    def __init__(self, max_tokens, start_tokens, maxlen, model, tokenizer,device, topk):\n","        self.max_tokens = max_tokens\n","        self.start_tokens = start_tokens\n","        self.maxlen = maxlen\n","        self.model = model\n","        self.tokenizer = tokenizer\n","        self.device = device\n","        self.k = topk \n","\n","    def sample_from(self, logits):\n","        logits, indices = torch.topk(logits, k=self.k, sorted=True)\n","        return np.random.choice(indices.cpu().numpy())\n","\n","\n","    def gen_poem(self):\n","        start_tokens = [_ for _ in self.start_tokens]\n","        num_tokens_generated = 0\n","        tokens_generated = []\n","        while num_tokens_generated <= self.max_tokens:\n","            pad_len = self.maxlen - len(start_tokens)\n","            sample_index = len(start_tokens) - 1\n","            if pad_len < 0:\n","                x = start_tokens[:self.maxlen]\n","                sample_index = self.maxlen - 1\n","            elif pad_len > 0:\n","                x = start_tokens + [0] * pad_len\n","            else:\n","                x = start_tokens\n","            x = torch.tensor([x], device= self.device)\n","            y = self.model(x)\n","            sample_token = self.sample_from(y[0][sample_index])\n","            tokens_generated.append(sample_token)\n","            start_tokens.append(sample_token)\n","            num_tokens_generated = len(tokens_generated)\n","            # print(sample_token)\n","        output_token = [_ for _ in self.start_tokens + tokens_generated]\n","        poem = self.tokenizer.decode(output_token, skip_special_tokens=True)\n","        print(f\"generated text:\\n{poem}\\n\")"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JvpZbSZfG4iY","executionInfo":{"status":"ok","timestamp":1617074504653,"user_tz":-420,"elapsed":32274,"user":{"displayName":"Poeta El","photoUrl":"","userId":"07945809110756503030"}},"outputId":"59e4ed12-041b-455c-c45c-b0723f85179f"},"source":["num_token_generated = 65\n","hint = 'quê hương là một tiếng ve'\n","start_tokens = tokenizer.encode(hint)[:-1]\n","generator = TextGenerator(max_tokens= num_token_generated, start_tokens= start_tokens, maxlen= 300, model= model, tokenizer= tokenizer,device= device, topk= 1)\n","generator.gen_poem()"],"execution_count":30,"outputs":[{"output_type":"stream","text":["generated text:\n","quê hương là một tiếng ve\n","vi vu tiếng sáo trưa hè về thôn\n","quê hương là những tiếng chim\n","nối tình với đất của miền xa xôi\n","\n","quê hương là cả tình tôi\n","hương đồng gió nội đến từ ngày xưa\n","quê hương là tiếng thoi đưa\n","mùi trong tay mới sớm trưa ngọt ngào\n","\n","quê hương là những khát khao\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rrGV0VQWUh41"},"source":[""],"execution_count":null,"outputs":[]}]}